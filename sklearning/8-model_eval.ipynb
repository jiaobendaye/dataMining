{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1]\n",
      " [1 2]]\n",
      "准确率： 0.6666666666666666\n",
      "类别精度: [0.66666667 0.66666667]\n",
      "宏平均精度: 0.6666666666666666\n",
      "微平均召回率: 0.6666666666666666\n",
      "加权平均F1: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred = [0, 0, 0, 1, 1, 1]\n",
    "y_true = [0, 1, 0, 1, 1, 0]\n",
    "\n",
    "print(metrics.confusion_matrix(y_true, y_pred))\n",
    "print('准确率：', metrics.accuracy_score(y_true, y_pred))\n",
    "\n",
    "print('类别精度:', metrics.precision_score(y_true, y_pred, average=None))\n",
    "\n",
    "print('宏平均精度:', metrics.precision_score(y_true, y_pred, average=\"macro\"))\n",
    "print('微平均召回率:', metrics.recall_score(y_true, y_pred, average='micro'))\n",
    "print('加权平均F1:', metrics.f1_score(y_true, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained_variance_score 0.844682478959449\n",
      "r2 0.7827084927314459\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import explained_variance_score, r2_score\n",
    "y_pred = [3, -0.3, 2.2, 1.3]\n",
    "y_true = [2.3, 0, 2.0, 1.0]\n",
    "print('explained_variance_score', explained_variance_score(y_true, y_pred))\n",
    "print('r2', r2_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 虚拟估计器产生基准得分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个不平衡的数据\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "y[y != 1] = -1\n",
    "X_train, X_test, y_train, y_test = train_~test_split(X, y, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liner svc classifier score: 0.631578947368421\n",
      "Dummy classifier score: 0.5789473684210527\n"
     ]
    }
   ],
   "source": [
    "#比较线性svm和虚拟估计器的得分\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "print('liner svc classifier score:', svc.score(X_test, y_test))\n",
    "\n",
    "dummy = DummyClassifier(strategy='most_frequent', random_state=0)\n",
    "dummy.fit(X_train, y_train)\n",
    "print('Dummy classifier score:', dummy.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf svc classifier score: 0.9736842105263158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "svcrbf = SVC(kernel='rbf', C=1).fit(X_train, y_train)\n",
    "print('rbf svc classifier score:', svcrbf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 过拟合与交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 4], [2 0]\n",
      "[1 4 3], [0 2]\n",
      "[4 0 2], [1 3]\n",
      "[2 4 0], [3 1]\n"
     ]
    }
   ],
   "source": [
    "#随机排列交叉yanzheng\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "X = np.arange(5)\n",
    "ss = ShuffleSplit(n_splits=4,test_size=0.4, random_state=0)\n",
    "for train_index, test_index in ss.split(X):\n",
    "    print('%s, %s' % (train_index, test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 6 7 8 9], [0 1 4 5]\n",
      "[0 1 3 4 5 8 9], [2 6 7]\n",
      "[0 1 2 4 5 6 7], [3 8 9]\n"
     ]
    }
   ],
   "source": [
    "# 分层K折交叉验证,用于数据不平衡\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "X = np.arange(10)\n",
    "y = [0,0,0,0,1,1,1,1,1,1]\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=False)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print('%s, %s' % (train_index, test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5], [0 1 2 3]\n",
      "[2 3], [0 1 4 5]\n",
      "[0 1], [2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "#留P分组\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "X = np.arange(6)\n",
    "y = [1, 1, 1,  2, 2, 2]\n",
    "groups = [1, 1, 2, 2, 3, 3]\n",
    "lpgo = LeavePGroupsOut(n_groups=2)\n",
    "for train_index, test_index in lpgo.split(X, y, groups):\n",
    "    print('%s, %s' % (train_index, test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1], [2 3]\n",
      "[1 2 3], [4 5]\n",
      "[3 4 5], [6 7]\n"
     ]
    }
   ],
   "source": [
    "#时间序列的分割\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "X = np.array([[1,2],[3,4],[1,2],[3,4],[1,2],[3,4],[2,2],[4,6]])\n",
    "y = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "tscv = TimeSeriesSplit(n_splits=3, max_train_size=3)\n",
    "for train_index, test_index in tscv.split(X, y):\n",
    "    print('%s, %s' % (train_index, test_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交叉验证的综合评分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73333333 0.83333333 0.56666667 0.53333333 0.66666667]\n",
      "Accuracy: 0.67(+/-0.22)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svc2 = SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(svc2, iris.data, iris.target, cv=5)\n",
    "print(scores)\n",
    "\n",
    "print(\"Accuracy: %0.2f(+/-%0.2f)\" %(scores.mean(), scores.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58333333, 0.77777778, 0.49935815, 0.52488688, 0.6031746 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#指定打分方式\n",
    "from sklearn import metrics\n",
    "scores = cross_val_score(svc2, iris.data, iris.target, cv=5, scoring='f1_macro')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64444444, 0.6       , 0.68888889])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#指定交叉验证迭代器，\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "n_samples = iris.data.shape[0]\n",
    "ss = ShuffleSplit(n_splits=3, test_size=0.3, random_state=0)\n",
    "cross_val_score(svc2, iris.data, iris.target, cv=ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fit_time', 'score_time', 'test_f1_macro', 'test_f1_micro']\n",
      "[0.00052357 0.00070524 0.00041914 0.00039625 0.00045466 0.0004797\n",
      " 0.000633   0.0005784  0.0004375  0.00043941]\n",
      "[0.00075221 0.00062609 0.00066018 0.00144672 0.00065017 0.00109005\n",
      " 0.00102019 0.00068069 0.0006566  0.00084209]\n",
      "f1_micro: [0.73333333 0.73333333 0.8        0.86666667 0.73333333 0.4\n",
      " 0.66666667 0.46666667 0.73333333 0.66666667]\n",
      "f1_macro: [0.58333333 0.58333333 0.72049689 0.82954545 0.65909091 0.38914027\n",
      " 0.66063348 0.44444444 0.72222222 0.53416149]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "clf = SVC(kernel='linear', C=1, random_state=0)\n",
    "scores = cross_validate(clf, iris.data, iris.target,\n",
    "                        scoring=['f1_micro', 'f1_macro'],\n",
    "                        cv=10, return_train_score=False)\n",
    "print(sorted(scores.keys()))\n",
    "print(scores['fit_time'])\n",
    "print(scores['score_time'])\n",
    "print('f1_micro:', scores['test_f1_micro'])\n",
    "print('f1_macro:', scores['test_f1_macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
